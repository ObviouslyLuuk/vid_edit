{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downscale video first, but keep the aspect ratio\n",
    "# Get current dimensions from vid.mp4\n",
    "current_dimensions = os.popen('ffprobe -v error -select_streams v:0 -show_entries stream=width,height -of csv=s=x:p=0 vid.mp4').read().split('x')\n",
    "current_dimensions = (int(current_dimensions[0]), int(current_dimensions[1]))\n",
    "print('Current dimensions:', current_dimensions)\n",
    "\n",
    "# Get new dimensions, making the smallest dimension 256\n",
    "new_dimensions = (256, 256)\n",
    "if current_dimensions[0] > current_dimensions[1]:\n",
    "    new_dimensions = (int(256 * current_dimensions[0] / current_dimensions[1]) // 2 * 2, 256)\n",
    "else:\n",
    "    new_dimensions = (256, int(256 * current_dimensions[1] / current_dimensions[0]) // 2 * 2)\n",
    "print('New dimensions:', new_dimensions)\n",
    "\n",
    "# Downscale video, using subprocess, and capture output in case of error\n",
    "# Remove old file if it exists\n",
    "if os.path.exists('vid_downscaled.mp4'):\n",
    "    os.remove('vid_downscaled.mp4')\n",
    "command = 'ffmpeg -i vid.mp4 -vf scale=' + str(new_dimensions[0]) + ':' + str(new_dimensions[1]) + ' vid_downscaled.mp4'\n",
    "output = subprocess.run(command, shell=True, capture_output=True)\n",
    "if output.returncode != 0:\n",
    "    print('Error:', output.stderr.decode('utf-8'))\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use ffmpeg to convert a video to a series of images\n",
    "target_dir = 'images'\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "# Remove old files if they exist\n",
    "for file in os.listdir(target_dir):\n",
    "    os.remove(os.path.join(target_dir, file))\n",
    "vid_path = 'vid_downscaled.mp4'\n",
    "# Get fps of video\n",
    "fps = os.popen(f'ffprobe -v error -select_streams v -of default=noprint_wrappers=1:nokey=1 -show_entries stream=r_frame_rate {vid_path}').read().strip().split('/')\n",
    "print(fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(f'ffmpeg -i {vid_path} -vf fps={fps[0]}/{fps[1]} {target_dir}/%04d.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread('images/0001.png')\n",
    "img2 = cv2.imread('images/0002.png')\n",
    "img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
    "img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
    "imgs = np.stack([img1, img2], axis=0) # (B, H, W, C)\n",
    "h, w, c = imgs.shape[1:]\n",
    "crop = np.array([[50,50], [100,100]]) # (B, 2)\n",
    "sliced = np.zeros_like(imgs)\n",
    "# for i in range(2):\n",
    "#     sliced[i, crop[i,0]:crop[i,0]+h, crop[i,1]:crop[i,1]+w] = imgs[i, crop[i,0]:crop[i,0]+h, crop[i,1]:crop[i,1]+w]\n",
    "\n",
    "# Create a grid of indices\n",
    "batch_indices = np.arange(imgs.shape[0])[:, None, None]\n",
    "row_indices = np.arange(h)[None, :, None]\n",
    "col_indices = np.arange(w)[None, None, :]\n",
    "\n",
    "# Calculate the indices for the magnified image\n",
    "row_indices = row_indices + crop[:, 1][:, None, None]\n",
    "col_indices = col_indices + crop[:, 0][:, None, None]\n",
    "\n",
    "# Remove indices that are out of bounds\n",
    "row_indices = np.clip(row_indices, 0, h - 1)\n",
    "col_indices = np.clip(col_indices, 0, w - 1)\n",
    "\n",
    "# Use advanced indexing to crop the magnified image\n",
    "sliced = imgs[batch_indices, row_indices, col_indices, :]\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].imshow(sliced[0])\n",
    "ax[1].imshow(sliced[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def magnify(img, center, factor):\n",
    "    \"\"\"Return the image magnified by factor, from center as the reference point, cropped to original size\"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    magnified_img = cv2.resize(img, (int(w*factor), int(h*factor)), interpolation=cv2.INTER_LINEAR)\n",
    "    # Crop to original size h, w, centered around center\n",
    "    magnified_center = (int(center[0]*factor), int(center[1]*factor)) # Adjust center for magnification\n",
    "    # Get upper left corner in magnified coordinates\n",
    "    UL_corner = (magnified_center[0]-center[0], magnified_center[1]-center[1])\n",
    "    magnified_img = magnified_img[UL_corner[1]:UL_corner[1]+h, UL_corner[0]:UL_corner[0]+w]\n",
    "    return magnified_img\n",
    "\n",
    "def magnify_tensor(img, center, factor):\n",
    "    \"\"\"Same as magnify, but for tensors of shape (B, H, W, C). Accept center to be either tuple: (x,y) or tensor: (B,2) for different centers for each image\"\"\"\n",
    "    assert len(img.shape) == 4, 'Input tensor must have shape (B, H, W, C)'\n",
    "    h, w = img.shape[1:3]\n",
    "    img = torch.tensor(img).permute(0, 3, 1, 2) # (B, C, H, W)\n",
    "    magnified_img = torchvision.transforms.functional.resize(img, (int(h*factor), int(w*factor)), interpolation=Image.BILINEAR).permute(0, 2, 3, 1).numpy() # (B, H, W, C)\n",
    "    if isinstance(center, tuple):\n",
    "        center = np.array(center)[None, :] # Convert to tensor shape (1,2)\n",
    "    else:\n",
    "        assert center.shape[0] == img.shape[0], 'Center must be tensor of shape (B,2)'\n",
    "    # Adjust center for magnification\n",
    "    magnified_center = (center*factor).astype(int)\n",
    "    # Get upper left corner in magnified coordinates\n",
    "    UL_corner = magnified_center - center\n",
    "    batch_indices = np.arange(img.shape[0])[:, None, None]\n",
    "    row_indices = np.arange(h)[None, :, None]\n",
    "    col_indices = np.arange(w)[None, None, :]\n",
    "    row_indices = row_indices + UL_corner[:, 1][:, None, None]\n",
    "    col_indices = col_indices + UL_corner[:, 0][:, None, None]\n",
    "    magnified_img = magnified_img[batch_indices, row_indices, col_indices, :]\n",
    "    return magnified_img\n",
    "\n",
    "def get_circle_mask(h, w, center, radius):\n",
    "    \"\"\"Return a mask for a circle with center and radius\"\"\"\n",
    "    mask = np.zeros((h, w), np.uint8)\n",
    "    cv2.circle(mask, center, radius, 255, -1, cv2.LINE_AA)\n",
    "    return mask\n",
    "\n",
    "def get_circle_mask_tensor(h, w, center, radius):\n",
    "    \"\"\"Same as get_circle_mask, but return (B, H, W) tensor. h and w should be constant, center (B, 2) and radius (B)\"\"\"\n",
    "    assert isinstance(center, np.ndarray), 'center must be numpy array'\n",
    "    assert isinstance(radius, np.ndarray), 'radius must be numpy array'\n",
    "    row_indices = np.arange(h)[None, :, None]\n",
    "    col_indices = np.arange(w)[None, None, :]\n",
    "    row_indices = row_indices - center[:, 1][:, None, None]\n",
    "    col_indices = col_indices - center[:, 0][:, None, None]\n",
    "    mask = row_indices**2 + col_indices**2 <= radius[:, None, None]**2\n",
    "    return mask.astype(np.uint8)\n",
    "    \n",
    "\n",
    "def get_pill_mask(h, w, center, height, width, angle):\n",
    "    \"\"\"Return a mask for a pill shape with center, height, width, and angle\"\"\"\n",
    "    mask = np.zeros((h, w), np.uint8)\n",
    "    # Create a rotated rectangle\n",
    "    rect_height = height - width # Height of the rectangle part of the pill\n",
    "    rect = ((center[0], center[1]), (width, rect_height), angle)\n",
    "    box = cv2.boxPoints(rect)\n",
    "    box = np.intp(box)\n",
    "    cv2.drawContours(mask, [box], 0, 255, -1)\n",
    "    # Place a circle at each end of the pill, in the middle of the width, to make it rounded\n",
    "    # To do this, interpolate halfway between the two corners at each end\n",
    "    # First end\n",
    "    end1 = (box[1] + box[2]) // 2\n",
    "    cv2.circle(mask, tuple(end1), width//2, 255, -1, cv2.LINE_AA)\n",
    "    # Second end\n",
    "    end2 = (box[0] + box[3]) // 2\n",
    "    cv2.circle(mask, tuple(end2), width//2, 255, -1, cv2.LINE_AA)\n",
    "    return mask\n",
    "\n",
    "def feather_edges(img, magnified, mask, feather_size=10):\n",
    "    \"\"\"Return image with magnified on top of img, feathered edges\"\"\"    \n",
    "    # Apply Gaussian blur to the mask to create feathered edges\n",
    "    # feathered_mask = cv2.GaussianBlur(mask, (feather_size*2+1, feather_size*2+1), 0)\n",
    "    # Use separable filter for faster processing\n",
    "    feathered_mask = cv2.sepFilter2D(mask, -1, cv2.getGaussianKernel(feather_size*2+1, 0), cv2.getGaussianKernel(feather_size*2+1, 0))\n",
    "    # Using scipy instead of cv2\n",
    "    # feathered_mask = scipy.ndimage.gaussian_filter(mask, sigma=feather_size)\n",
    "\n",
    "    # Normalize feathered mask to be between 0 and 1\n",
    "    feathered_mask = feathered_mask / 255\n",
    "\n",
    "    # Add dimension to feathered mask for broadcasting\n",
    "    feathered_mask = feathered_mask[:, :, None]\n",
    "\n",
    "    # Blend the magnified with the image using the feathered mask\n",
    "    # The magnified is displayed where the mask is 1, and the image where the mask is 0\n",
    "    # And the values in between are interpolated\n",
    "    # This is done for each color channel\n",
    "    blended = img*(1-feathered_mask) + magnified*feathered_mask\n",
    "    return blended.astype(np.uint8)\n",
    "\n",
    "def feather_edges_tensor(img, magnified, mask, feather_size=10):\n",
    "    \"\"\"Same as feather_edges, but for tensors of shape (B, H, W, C)\"\"\"\n",
    "    assert len(img.shape) == 4, 'Input tensor must have shape (B, H, W, C)'\n",
    "    assert img.shape == magnified.shape, 'img and magnified must have the same shape'\n",
    "    mask = torch.tensor(mask).unsqueeze(1).float() # (B, 1, H, W)\n",
    "    # Apply Gaussian blur to the mask to create feathered edges\n",
    "    # Use separable filter for faster processing\n",
    "    kernel = torch.tensor(cv2.getGaussianKernel(feather_size*2+1, 0)).float() # (2*feather_size+1, 1)\n",
    "    kernel = kernel.unsqueeze(0).unsqueeze(0) # (1, 1, 2*feather_size+1, 1)\n",
    "    feathered_mask = torch.nn.functional.conv2d(mask, kernel, stride=1, padding=feather_size) # (B, 1, H, W)\n",
    "    feathered_mask = torch.nn.functional.conv2d(feathered_mask, kernel.permute(0, 1, 3, 2), stride=1, padding=feather_size) # (B, 1, H, W)\n",
    "    feathered_mask = feathered_mask.squeeze(1)[:, feather_size:-feather_size, feather_size:-feather_size, None].numpy() # (B, H, W, 1)\n",
    "\n",
    "    # Normalize feathered mask to be between 0 and 1\n",
    "    if feathered_mask.max() > 1:\n",
    "        feathered_mask = feathered_mask / 255\n",
    "    # Blend the magnified with the image using the feathered mask\n",
    "    blended = img*(1-feathered_mask) + magnified*feathered_mask\n",
    "    return blended.astype(np.uint8)\n",
    "\n",
    "# Batch image test\n",
    "img1 = cv2.imread('images/0015.png')\n",
    "img2 = cv2.imread('images/0016.png')\n",
    "img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
    "img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
    "imgs = np.stack([img1, img2], axis=0)\n",
    "# center = (100, 100)\n",
    "center = np.array([[100, 100], [100, 300]])\n",
    "magnified_imgs = magnify_tensor(imgs, center, 1.5)\n",
    "\n",
    "# fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "# axs[0].imshow(magnified_imgs[0])\n",
    "# axs[1].imshow(magnified_imgs[1])\n",
    "# plt.show()\n",
    "\n",
    "# Create a circle mask\n",
    "h, w = imgs.shape[1:3]\n",
    "radius = np.array([200])\n",
    "mask = get_circle_mask_tensor(h, w, center, radius)\n",
    "\n",
    "# fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "# axs[0].imshow(mask[0])\n",
    "# axs[1].imshow(mask[1])\n",
    "# plt.show()\n",
    "\n",
    "# Feathered edges\n",
    "feathered = feather_edges_tensor(imgs, magnified_imgs, mask, feather_size=30)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axs[0].imshow(feathered[0])\n",
    "axs[1].imshow(feathered[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single image test\n",
    "img = cv2.imread('images/0015.png')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "center = (0.54,0.75)\n",
    "center = (int(center[0]*img.shape[1]), int(center[1]*img.shape[0]))\n",
    "radius = 0.74\n",
    "radius = int(radius*img.shape[1])\n",
    "feather_size = 0.19\n",
    "feather_size = int(feather_size*img.shape[1])\n",
    "magnified = magnify(img, center, 1.5)\n",
    "# mask = get_circle_mask(img.shape[0], img.shape[1], center, radius)\n",
    "mask = get_pill_mask(img.shape[0], img.shape[1], center, radius*2, radius, 0)\n",
    "plt.imshow(mask, cmap='gray')\n",
    "plt.show()\n",
    "feathered_circle = feather_edges(img, magnified, mask, feather_size=feather_size)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "ax.imshow(feathered_circle)\n",
    "# Show cross where the center is\n",
    "ax.plot(center[0], center[1], 'rx')\n",
    "# Show dotted circle where the circle is\n",
    "circle = plt.Circle(center, radius, color='r', fill=False, linestyle='dotted')\n",
    "ax.add_artist(circle)\n",
    "# Show area that is feathered (the radius of the circle plus the feather size)\n",
    "circle = plt.Circle(center, radius-feather_size, color='b', fill=False, linestyle='dotted')\n",
    "ax.add_artist(circle)\n",
    "circle = plt.Circle(center, radius+feather_size, color='b', fill=False, linestyle='dotted')\n",
    "ax.add_artist(circle)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another method; instead of feathering, we warp the image\n",
    "# This means we do a non-linear transformation of the image, where the area around the center is magnified\n",
    "# Which warps into the rest of the image\n",
    "def warp_image(img, center, factor):\n",
    "    \"\"\"Return the image warped by factor, from center as the reference point, cropped to original size\"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    # Create a grid of coordinates\n",
    "    x, y = np.meshgrid(np.arange(w), np.arange(h))\n",
    "    # Convert to float32\n",
    "    x = x.astype(np.float32)\n",
    "    y = y.astype(np.float32)\n",
    "    # Normalize to -1 to 1, with the variable 'center' as the origin\n",
    "    x = (x - center[0]) / w # shape: (h, w)\n",
    "    y = (y - center[1]) / h # shape: (h, w)\n",
    "    # Calculate the distance from the center\n",
    "    r = np.sqrt(x**2 + y**2) # Distance from center shape: (h, w)\n",
    "    # Calculate the new distance from the center\n",
    "    r = r ** (factor-1)\n",
    "    # Calculate the new coordinates\n",
    "    x = x * r * w + center[0]\n",
    "    y = y * r * h + center[1]\n",
    "\n",
    "    warped = cv2.remap(img, x, y, cv2.INTER_LINEAR)\n",
    "    return warped\n",
    "\n",
    "img = cv2.imread('images/0015.png')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "center = (0.54,0.75)\n",
    "center = (int(center[0]*img.shape[1]), int(center[1]*img.shape[0]))\n",
    "factor = 1.1\n",
    "warped = warp_image(img, center, factor)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].imshow(img)\n",
    "ax[1].imshow(warped)\n",
    "# Show cross where the center is\n",
    "ax[1].plot(center[0], center[1], 'rx')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feather_magnify(img, center, radius, feather_size):\n",
    "    # Magnify the circle\n",
    "    magnified = magnify_tensor(img, center, 1.5)\n",
    "    # Feather the edges\n",
    "    mask = get_circle_mask(img.shape[0], img.shape[1], center, radius)\n",
    "    # mask = get_pill_mask(img.shape[0], img.shape[1], center, 150, 150, 0)\n",
    "    feathered_circle = feather_edges_tensor(img, magnified, mask, feather_size=feather_size)\n",
    "    img = feathered_circle\n",
    "    return img\n",
    "\n",
    "def warp_magnify(img, center, factor):\n",
    "    # Warp the image\n",
    "    warped = warp_image(img, center, factor)\n",
    "    img = warped\n",
    "    return img\n",
    "\n",
    "# Process all images and save them to a new directory\n",
    "new_dir = 'processed_images'\n",
    "os.makedirs(new_dir, exist_ok=True)\n",
    "# Make target dir empty\n",
    "os.system(f'rm -rf {new_dir}/*')\n",
    "for img_path in tqdm(os.listdir(target_dir)[:]):\n",
    "    img = cv2.imread(f'{target_dir}/{img_path}')\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    # processed_img = feather_magnify(img, center=center, radius=radius, feather_size=feather_size)\n",
    "    processed_img = warp_magnify(img, center=center, factor=1.2)\n",
    "    processed_img = cv2.cvtColor(processed_img, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite(f'{new_dir}/{img_path}', processed_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the processed images back into a video\n",
    "# Remove the target file if it already exists\n",
    "if os.path.exists('vid_out.mp4'):\n",
    "    os.remove('vid_out.mp4')\n",
    "os.system(f'ffmpeg -i {new_dir}/%04d.png -vf fps={fps[0]}/{fps[1]} -c:v libx264 -profile:v high -crf 20 -pix_fmt yuv420p vid_out.mp4')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
